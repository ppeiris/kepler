{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different learning rate schedules and momentum parameters\n",
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "          \"constant with Nesterov's momentum\",\n",
    "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\",\n",
    "          \"inv-scaling with Nesterov's momentum\", \"adam\"]\n",
    "\n",
    "plot_args = [{'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'green', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '-'},\n",
    "             {'c': 'red', 'linestyle': '--'},\n",
    "             {'c': 'green', 'linestyle': '--'},\n",
    "             {'c': 'blue', 'linestyle': '--'},\n",
    "             {'c': 'black', 'linestyle': '-'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_on_dataset(X, y, ax, name):\n",
    "    # for each dataset, plot learning for each learning strategy\n",
    "    print(\"\\nlearning on dataset %s\" % name)\n",
    "    ax.set_title(name)\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    mlps = []\n",
    "    if name == \"digits\":\n",
    "        # digits is larger but converges fairly quickly\n",
    "        max_iter = 15\n",
    "    else:\n",
    "        max_iter = 400\n",
    "\n",
    "    for label, param in zip(labels, params):\n",
    "        print(\"training: %s\" % label)\n",
    "        mlp = MLPClassifier(verbose=0, random_state=0, hidden_layer_sizes=(50, ),\n",
    "                            max_iter=max_iter, **param)\n",
    "        mlp.fit(X, y)\n",
    "        mlps.append(mlp)\n",
    "        print(\"Training set score: %f\" % mlp.score(X, y))\n",
    "        print(\"Training set loss: %f\" % mlp.loss_)\n",
    "    for mlp, label, args in zip(mlps, labels, plot_args):\n",
    "            ax.plot(mlp.loss_curve_, label=label, **args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning on dataset iris\n",
      "training: constant learning-rate\n",
      "Training set score: 0.980000\n",
      "Training set loss: 0.125365\n",
      "training: constant with momentum\n",
      "Training set score: 0.986667\n",
      "Training set loss: 0.051049\n",
      "training: constant with Nesterov's momentum\n",
      "Training set score: 0.706667\n",
      "Training set loss: 0.313523\n",
      "training: inv-scaling learning-rate\n",
      "Training set score: 0.333333\n",
      "Training set loss: 1.226688\n",
      "training: inv-scaling with momentum\n",
      "Training set score: 0.333333\n",
      "Training set loss: 1.106344\n",
      "training: inv-scaling with Nesterov's momentum\n",
      "Training set score: 0.333333\n",
      "Training set loss: 1.106485\n",
      "training: adam\n",
      "Training set score: 0.980000\n",
      "Training set loss: 0.050560\n",
      "\n",
      "learning on dataset digits\n",
      "training: constant learning-rate\n",
      "Training set score: 0.226489\n",
      "Training set loss: 1.922816\n",
      "training: constant with momentum\n",
      "Training set score: 0.343350\n",
      "Training set loss: 1.478224\n",
      "training: constant with Nesterov's momentum\n",
      "Training set score: 0.346132\n",
      "Training set loss: 1.474257\n",
      "training: inv-scaling learning-rate\n",
      "Training set score: 0.100723\n",
      "Training set loss: 2.338942\n",
      "training: inv-scaling with momentum\n",
      "Training set score: 0.195326\n",
      "Training set loss: 2.175554\n",
      "training: inv-scaling with Nesterov's momentum\n",
      "Training set score: 0.209238\n",
      "Training set loss: 2.292615\n",
      "training: adam\n",
      "Training set score: 0.363383\n",
      "Training set loss: 1.506754\n",
      "\n",
      "learning on dataset circles\n",
      "training: constant learning-rate\n",
      "Training set score: 0.480000\n",
      "Training set loss: 0.695520\n",
      "training: constant with momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.714482\n",
      "training: constant with Nesterov's momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.708279\n",
      "training: inv-scaling learning-rate\n",
      "Training set score: 0.600000\n",
      "Training set loss: 0.704001\n",
      "training: inv-scaling with momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.714698\n",
      "training: inv-scaling with Nesterov's momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.715664\n",
      "training: adam\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.702575\n",
      "\n",
      "learning on dataset moons\n",
      "training: constant learning-rate\n",
      "Training set score: 0.850000\n",
      "Training set loss: 0.357327\n",
      "training: constant with momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.712959\n",
      "training: constant with Nesterov's momentum\n",
      "Training set score: 0.860000\n",
      "Training set loss: 0.359904\n",
      "training: inv-scaling learning-rate\n",
      "Training set score: 0.520000\n",
      "Training set loss: 0.702784\n",
      "training: inv-scaling with momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.714058\n",
      "training: inv-scaling with Nesterov's momentum\n",
      "Training set score: 0.500000\n",
      "Training set loss: 0.714992\n",
      "training: adam\n",
      "Training set score: 0.850000\n",
      "Training set loss: 0.357459\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "# load / generate some toy datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "data_sets = [(iris.data, iris.target),\n",
    "             (digits.data, digits.target),\n",
    "             datasets.make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "             datasets.make_moons(noise=0.3, random_state=0)]\n",
    "\n",
    "for ax, data, name in zip(axes.ravel(), data_sets, ['iris', 'digits',\n",
    "                                                    'circles', 'moons']):\n",
    "    plot_on_dataset(*data, ax=ax, name=name)\n",
    "\n",
    "fig.legend(ax.get_lines(), labels=labels, ncol=3, loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": false,
   "toc_threshold": "2",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
